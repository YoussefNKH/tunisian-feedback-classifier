{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SA0dF6KL7yex"
      },
      "source": [
        "# **CRISP-DM Methodology for Data Science:**\n",
        "This methodology includes 5 steps:\n",
        "* ***Step 1- Business & Data Understanding***: The goal of the first is to identify Variables (Number, Types, Quality), Classes (Number of classes) and Volume (Number of samples).\n",
        "* ***Step 2- Data Preparation***: This step aims to clean, analyze, encode, normalize and split data.\n",
        "* ***Step 3- Machine Learning***: The implementation of machine learning algorithms.\n",
        "* ***Step 4- Performance Evaluation***: Evaluate the peformance using metrics.\n",
        "* ***Step 5- Deployment***: Saving model and implementing a web interface (API, Service)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNeMJZGe8EkT"
      },
      "source": [
        "# **Step 1- Business & Data Understanding**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-epNxQRq7uu6",
        "outputId": "bf5c3a14-d465-4dc4-9314-5660ad221882"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comment_Text_Arabic</th>\n",
              "      <th>Problem_Source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>يا ولادي شريت تاليفون جديد، بعد جمعة البطارية ...</td>\n",
              "      <td>المنتج</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>الطلبية وصلتني ناقصة، و خدمة العملاء ما يجاوبو...</td>\n",
              "      <td>الخدمة</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>الغسالة من أول استعمال تعمل في حس غريب و ما تن...</td>\n",
              "      <td>المنتج</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>طلبت حذاء، جابولي قياس خاطئ و باش نبدل حكاية!</td>\n",
              "      <td>الخدمة</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>الخامة نتاع التيشرت هذا خايبة برشا، لبستين و ت...</td>\n",
              "      <td>المنتج</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 Comment_Text_Arabic Problem_Source\n",
              "0  يا ولادي شريت تاليفون جديد، بعد جمعة البطارية ...         المنتج\n",
              "1  الطلبية وصلتني ناقصة، و خدمة العملاء ما يجاوبو...         الخدمة\n",
              "2  الغسالة من أول استعمال تعمل في حس غريب و ما تن...         المنتج\n",
              "3      طلبت حذاء، جابولي قياس خاطئ و باش نبدل حكاية!         الخدمة\n",
              "4  الخامة نتاع التيشرت هذا خايبة برشا، لبستين و ت...         المنتج"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv(\"finals.csv\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3W8tYJFCXQ-j"
      },
      "source": [
        "this dataset contains the following variables:\n",
        "\n",
        "\n",
        "*   **Comment_Text_Arabic**: which contains the comments\n",
        "*   **Problem_Source**: that contains the labels (2 classes of problem came from : product(المنتج) and service(الخدمة))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UU9O3_V5Bc76",
        "outputId": "ac82d4fe-0701-4ae1-e1ce-dfe71cd661ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1036 entries, 0 to 1035\n",
            "Data columns (total 2 columns):\n",
            " #   Column               Non-Null Count  Dtype \n",
            "---  ------               --------------  ----- \n",
            " 0   Comment_Text_Arabic  1036 non-null   object\n",
            " 1   Problem_Source       1036 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 16.3+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgLHdHpNYc5E"
      },
      "source": [
        "The data includes 1036 samples with two type of variables:\n",
        "* *Features* Data which are:\n",
        "  * Comment_Text_Arabic 1036 non-null object\n",
        "* *Labels* Data which are:\n",
        "  * Problem_Source 1036 non-null  object"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jxsix2J2DAKF"
      },
      "source": [
        "# **Step 2 - Data Preparation**\n",
        "\n",
        "There is no missed data, but we have to encode the text into numerical vectors. This is what we call \"Word Embedding\". Then, we will split the data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qW4vr4SjDJqE"
      },
      "source": [
        "## **2.1. Cleaning using Re and NLTK**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "D6HRtldPIo2s",
        "outputId": "3ba9bc2b-1b81-41a5-89ac-6e49e4a5d999"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\youss.YOUSSEF\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comment_Text_Arabic</th>\n",
              "      <th>Problem_Source</th>\n",
              "      <th>cleaned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>يا ولادي شريت تاليفون جديد، بعد جمعة البطارية ...</td>\n",
              "      <td>المنتج</td>\n",
              "      <td>ولادي شريت تاليفون جديد، جمعه البطاريه طاحت جمله</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>الطلبية وصلتني ناقصة، و خدمة العملاء ما يجاوبو...</td>\n",
              "      <td>الخدمة</td>\n",
              "      <td>الطلبيه وصلتني ناقصه، خدمه العملاء يجاوبوش</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>الغسالة من أول استعمال تعمل في حس غريب و ما تن...</td>\n",
              "      <td>المنتج</td>\n",
              "      <td>الغساله اول استعمال تعمل حس غريب تنظفش بالباهي</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>طلبت حذاء، جابولي قياس خاطئ و باش نبدل حكاية!</td>\n",
              "      <td>الخدمة</td>\n",
              "      <td>طلبت حذاء، جابولي قياس خاطء باش نبدل حكايه</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>الخامة نتاع التيشرت هذا خايبة برشا، لبستين و ت...</td>\n",
              "      <td>المنتج</td>\n",
              "      <td>الخامه نتاع التيشرت خايبه برشا، لبستين تريّش</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 Comment_Text_Arabic Problem_Source  \\\n",
              "0  يا ولادي شريت تاليفون جديد، بعد جمعة البطارية ...         المنتج   \n",
              "1  الطلبية وصلتني ناقصة، و خدمة العملاء ما يجاوبو...         الخدمة   \n",
              "2  الغسالة من أول استعمال تعمل في حس غريب و ما تن...         المنتج   \n",
              "3      طلبت حذاء، جابولي قياس خاطئ و باش نبدل حكاية!         الخدمة   \n",
              "4  الخامة نتاع التيشرت هذا خايبة برشا، لبستين و ت...         المنتج   \n",
              "\n",
              "                                            cleaned  \n",
              "0  ولادي شريت تاليفون جديد، جمعه البطاريه طاحت جمله  \n",
              "1        الطلبيه وصلتني ناقصه، خدمه العملاء يجاوبوش  \n",
              "2    الغساله اول استعمال تعمل حس غريب تنظفش بالباهي  \n",
              "3        طلبت حذاء، جابولي قياس خاطء باش نبدل حكايه  \n",
              "4      الخامه نتاع التيشرت خايبه برشا، لبستين تريّش  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "arabic_stopwords = set(stopwords.words('arabic'))\n",
        "\n",
        "def normalize_arabic(text):\n",
        "    text = re.sub(r'[إأآا]', 'ا', text)\n",
        "    text = re.sub(r'ى', 'ي', text)\n",
        "    text = re.sub(r'ؤ', 'ء', text)\n",
        "    text = re.sub(r'ئ', 'ء', text)\n",
        "    text = re.sub(r'ة', 'ه', text)\n",
        "    text = re.sub(r'[^؀-ۿ\\s]', '', text)  # Keep only Arabic characters\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "def clean_arabic_text(text):\n",
        "    text = normalize_arabic(text)\n",
        "    tokens = text.split()\n",
        "    tokens = [t for t in tokens if t not in arabic_stopwords]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Apply preprocessing\n",
        "df['cleaned'] = df['Comment_Text_Arabic'].apply(clean_arabic_text)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TI9ki7_eI-MO"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=1000)\n",
        "X_tfidf = vectorizer.fit_transform(df['cleaned']).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['Problem_Source'] = df['Problem_Source'].str.replace('\"', '', regex=False).str.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2nCwFPhVJPaY"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=1000)\n",
        "X = vectorizer.fit_transform(df['Comment_Text_Arabic']).toarray()\n",
        "y = df['Problem_Source']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzUQGraiJkvG",
        "outputId": "14b51aec-66c0-4e2b-ddf5-5a8de65efc1d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['المنتج', 'الخدمة'], dtype=object)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkMnlgnxJ7j-"
      },
      "source": [
        "## **2.2. Split of Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "l1aQi64PJsv7"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHJEZYtbKExK"
      },
      "source": [
        "# **Step 3 - Machine Learning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCp2dYTcKGaL",
        "outputId": "69777091-ae8c-40bc-c9a1-7d5c0bf84e51"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\youss.YOUSSEF\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes    import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm            import SVC\n",
        "#Inialization\n",
        "nb=GaussianNB()\n",
        "nn=MLPClassifier(hidden_layer_sizes=(20,20),activation=\"logistic\",solver='adam')\n",
        "linear_svm=SVC(kernel='linear')\n",
        "rbf_svm=SVC(kernel='rbf')\n",
        "sgd_svm=SVC(kernel='sigmoid')\n",
        "poly_svm=SVC(kernel='poly',degree=2)\n",
        "#Training\n",
        "nb.fit(X_train,y_train)\n",
        "nn.fit(X_train,y_train)\n",
        "linear_svm.fit(X_train,y_train)\n",
        "rbf_svm.fit(X_train,y_train)\n",
        "sgd_svm.fit(X_train,y_train)\n",
        "poly_svm.fit(X_train,y_train)\n",
        "#Prediction\n",
        "y_pred_nb=nb.predict(X_test)\n",
        "y_pred_nn=nn.predict(X_test)\n",
        "y_pred_rbf=rbf_svm.predict(X_test)\n",
        "y_pred_linear=linear_svm.predict(X_test)\n",
        "y_pred_sgd=sgd_svm.predict(X_test)\n",
        "y_pred_poly=poly_svm.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqvZC-uyKgyR"
      },
      "source": [
        "# **Step 4- Performance Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZC6gkAGKoxQ",
        "outputId": "557ec524-9699-4700-f921-d836929cc6d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "************ Performance of Naive Bayes *************\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      الخدمة       0.87      0.88      0.88        92\n",
            "      المنتج       0.90      0.90      0.90       116\n",
            "\n",
            "    accuracy                           0.89       208\n",
            "   macro avg       0.89      0.89      0.89       208\n",
            "weighted avg       0.89      0.89      0.89       208\n",
            "\n",
            "************ Performance of Neural Network *************\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      الخدمة       0.91      0.95      0.93        92\n",
            "      المنتج       0.96      0.92      0.94       116\n",
            "\n",
            "    accuracy                           0.93       208\n",
            "   macro avg       0.93      0.93      0.93       208\n",
            "weighted avg       0.93      0.93      0.93       208\n",
            "\n",
            "************ Performance of Linear SVM *************\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      الخدمة       0.91      0.91      0.91        92\n",
            "      المنتج       0.93      0.93      0.93       116\n",
            "\n",
            "    accuracy                           0.92       208\n",
            "   macro avg       0.92      0.92      0.92       208\n",
            "weighted avg       0.92      0.92      0.92       208\n",
            "\n",
            "************ Performance of RBF SVM *************\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      الخدمة       0.92      0.93      0.93        92\n",
            "      المنتج       0.95      0.94      0.94       116\n",
            "\n",
            "    accuracy                           0.94       208\n",
            "   macro avg       0.94      0.94      0.94       208\n",
            "weighted avg       0.94      0.94      0.94       208\n",
            "\n",
            "************ Performance of SGD SVM *************\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      الخدمة       0.91      0.90      0.91        92\n",
            "      المنتج       0.92      0.93      0.93       116\n",
            "\n",
            "    accuracy                           0.92       208\n",
            "   macro avg       0.92      0.92      0.92       208\n",
            "weighted avg       0.92      0.92      0.92       208\n",
            "\n",
            "************ Performance of Poly SVM *************\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      الخدمة       0.93      0.93      0.93        92\n",
            "      المنتج       0.95      0.95      0.95       116\n",
            "\n",
            "    accuracy                           0.94       208\n",
            "   macro avg       0.94      0.94      0.94       208\n",
            "weighted avg       0.94      0.94      0.94       208\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(\"************ Performance of Naive Bayes *************\")\n",
        "print(classification_report(y_test, y_pred_nb))\n",
        "\n",
        "print(\"************ Performance of Neural Network *************\")\n",
        "print(classification_report(y_test, y_pred_nn))\n",
        "\n",
        "print(\"************ Performance of Linear SVM *************\")\n",
        "print(classification_report(y_test, y_pred_linear))\n",
        "\n",
        "print(\"************ Performance of RBF SVM *************\")\n",
        "print(classification_report(y_test, y_pred_rbf))\n",
        "\n",
        "print(\"************ Performance of SGD SVM *************\")\n",
        "print(classification_report(y_test, y_pred_sgd))\n",
        "\n",
        "print(\"************ Performance of Poly SVM *************\")\n",
        "print(classification_report(y_test, y_pred_poly))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjSM8BRESh_K"
      },
      "source": [
        "### ✅ Neural Network\n",
        "\n",
        "The neural network showed excellent performance with high accuracy on both classes.  \n",
        "It's a great choice when you have more data or plan to handle more complex tasks later.  \n",
        "It’s flexible and scalable, though it requires more resources and tuning expertise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDvS027Z2cxP",
        "outputId": "12ecf636-b175-4302-a075-51c5ecdecfbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The predicted problem source for the text is: المنتج\n"
          ]
        }
      ],
      "source": [
        "#########################TEST################################\n",
        "text = \"برودوي مجا شي حكايتو فارغة منغير متشريو \"\n",
        "\n",
        "cleaned_text = clean_arabic_text(text)\n",
        "\n",
        "text_vectorized = vectorizer.transform([cleaned_text]).toarray()\n",
        "\n",
        "prediction = nn.predict(text_vectorized)\n",
        "\n",
        "print(f\"The predicted problem source for the text is: {prediction[0]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKDRf9MueHTo"
      },
      "source": [
        "# **Step 5 - Deployment**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "U6_FMTcjSlqF"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"MLP_model.pkl\", \"wb\") as f:\n",
        "    pickle.dump(nn, f)\n",
        "with open(\"tfidf_vectorizer.pkl\", \"wb\") as f:\n",
        "    pickle.dump(vectorizer, f)\n",
        "with open(\"cleaner-text.pkl\",\"wb\") as f:\n",
        "  pickle.dump(clean_arabic_text,f)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
